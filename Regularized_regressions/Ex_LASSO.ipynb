{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r7I7X6eNB1E0"
   },
   "source": [
    "# Régression Régularisées : LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEEVHzXrB7JU"
   },
   "source": [
    "0. Importez les librairies usuelles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j67KpuCLBuSF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-mv63KxB_re"
   },
   "source": [
    "1. Chargez les données grâce à la commande suivante :\n",
    "\n",
    "```\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGEDyXXKCFvD"
   },
   "source": [
    "2. Créer un dataframe contenant les variables explicatives et un contenant uniquement la variable cible (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1585151514113,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "FvwTdZ0LB_PB",
    "outputId": "b0f0b105-c194-4105-a0f6-372f825a73e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
       "0        17.99         10.38  ...          0.4601                  0.11890\n",
       "1        20.57         17.77  ...          0.2750                  0.08902\n",
       "2        19.69         21.25  ...          0.3613                  0.08758\n",
       "3        11.42         20.38  ...          0.6638                  0.17300\n",
       "4        20.29         14.34  ...          0.2364                  0.07678\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1585151514115,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "lwhwy9u2MkZL",
    "outputId": "20ccaf14-d4e8-46b0-f37f-b6a69878b5bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
       "0          17.99         10.38  ...          0.4601                  0.11890\n",
       "1          20.57         17.77  ...          0.2750                  0.08902\n",
       "2          19.69         21.25  ...          0.3613                  0.08758\n",
       "3          11.42         20.38  ...          0.6638                  0.17300\n",
       "4          20.29         14.34  ...          0.2364                  0.07678\n",
       "..           ...           ...  ...             ...                      ...\n",
       "564        21.56         22.39  ...          0.2060                  0.07115\n",
       "565        20.13         28.25  ...          0.2572                  0.06637\n",
       "566        16.60         28.08  ...          0.2218                  0.07820\n",
       "567        20.60         29.33  ...          0.4087                  0.12400\n",
       "568         7.76         24.54  ...          0.2871                  0.07039\n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1969,
     "status": "ok",
     "timestamp": 1585151516253,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "DtxqVTjtCIHZ",
    "outputId": "b4cf39ae-df09-4ca8-d2d6-4b2e6b01972c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cancer\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(cancer.target, columns=[\"cancer\"])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1585151516254,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "7oGPlZchM2SP",
    "outputId": "228b7dd8-b7eb-45e6-aa95-538ec5222a49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: cancer, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.cancer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlHazT7SCObd"
   },
   "source": [
    "3. Séparer les données en une base d’apprentissage et une base de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yirkNz_pCLZ3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_df, y, test_size = 0.3, random_state=0, stratify=y)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc_fit = sc.fit(X_train)\n",
    "X_train = sc_fit.transform(X_train)\n",
    "X_test = sc_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Z8__rp8CT43"
   },
   "source": [
    "4. Générez un modèle de régression linéaire, un modèle lasso ou alpha vaut 1, un autre ou alpha = 0.01 et un dernier où alpha = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEb4PqlMCQf8"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "lin = LogisticRegression(penalty='none')\n",
    "lasso1 = Lasso(alpha = 1)\n",
    "lasso2 = Lasso(alpha = 0.01)\n",
    "lasso3 = Lasso(alpha = 0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3LxfJlwYCeiX"
   },
   "source": [
    "5. Entraînez ces modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1887,
     "status": "ok",
     "timestamp": 1585151522039,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "15ab6XWcCaZm",
    "outputId": "2d473149-ff08-442a-8d34-4cd98e7ee45d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.316213401503079, tolerance: 0.009296482412060299\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.fit(X_train, y_train)\n",
    "lasso1.fit(X_train, y_train)\n",
    "lasso2.fit(X_train, y_train)\n",
    "lasso3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIn_nvuqCi03"
   },
   "source": [
    "6. Produisez les scores de performance des quatres modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1585151535705,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "okoEdZuRObLd",
    "outputId": "f44fd6cf-b255-4e77-a5d8-951496670314"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Lin : 1.0 \n",
      " Score Lasso1 : 0.0 \n",
      " Score Lasso2 : 0.7429220259018634 \n",
      " Score Lasso3 : 0.7873832367745113\n"
     ]
    }
   ],
   "source": [
    "print(\"Score Lin : {} \\n Score Lasso1 : {} \\n Score Lasso2 : {} \\n Score Lasso3 : {}\".format(lin.score(X_train, y_train),\n",
    "                                                                                            lasso1.score(X_train, y_train),\n",
    "                                                                                            lasso2.score(X_train, y_train),\n",
    "                                                                                            lasso3.score(X_train,y_train),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1585151545283,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "2mYvFFlkCgpo",
    "outputId": "4aeef0eb-9ede-417c-a570-4d57c40eb99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Lin : 0.9532163742690059 \n",
      " Score Lasso1 : -2.479463961413408e-05 \n",
      " Score Lasso2 : 0.6974563639852517 \n",
      " Score Lasso3 : 0.7209498834514757\n"
     ]
    }
   ],
   "source": [
    "print(\"Score Lin : {} \\n Score Lasso1 : {} \\n Score Lasso2 : {} \\n Score Lasso3 : {}\".format(lin.score(X_test, y_test),\n",
    "                                                                                            lasso1.score(X_test, y_test),\n",
    "                                                                                            lasso2.score(X_test, y_test),\n",
    "                                                                                            lasso3.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m-KkFshTCogM"
   },
   "source": [
    "7. Comparez les coefficients des quatres modèles, quelles sont vos conclusions ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2246,
     "status": "ok",
     "timestamp": 1585151573223,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "EbiPe296Ck61",
    "outputId": "f2f61738-0a51-48dd-da7d-fb0a7763afa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd425ab9be0>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOAzDMIy8sMRhGIZh5MX/A55YbO1r6VycAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_lasso1 = pd.DataFrame({\"params\": lasso1.coef_, \n",
    "                                       \"model\": \"lasso Alpha = 1\", \n",
    "                                       \"index\": range(0, len(cancer_df.columns))})\n",
    "\n",
    "perf_lasso2 = pd.DataFrame({\"params\": lasso2.coef_, \n",
    "                                       \"model\": \"lasso Alpha = 0.01\", \n",
    "                                       \"index\": range(0, len(cancer_df.columns))})\n",
    "\n",
    "perf_lasso3 = pd.DataFrame({\"params\": lasso3.coef_, \n",
    "                                       \"model\": \"lasso Alpha = 0.0001\", \n",
    "                                       \"index\": range(0, len(cancer_df.columns))})\n",
    "\n",
    "\n",
    "perf_lin = pd.DataFrame({\"params\": lin.coef_[0], \n",
    "                                       \"model\": \"linear\", \n",
    "                                       \"index\": range(0, len(cancer_df.columns))})\n",
    "\n",
    "perf_compar = pd.concat([perf_lasso1,perf_lasso2,perf_lasso3,perf_lin])\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pointplot(x = 'index',y = 'params',hue = 'model', style = 'model', data = perf_compar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1552,
     "status": "ok",
     "timestamp": 1585151576965,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "brv4XONgoVhU",
    "outputId": "57a0e0c5-4bf9-4e35-e60e-8024e26867d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01284729, -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.04753953, -0.        ,  0.01690129,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.02975152,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.16475538, -0.06413935, -0.        ,  0.        , -0.01863447,\n",
       "       -0.        , -0.00682887, -0.14576274, -0.03778763, -0.00215121])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1503,
     "status": "ok",
     "timestamp": 1585151577395,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "qbi8gGSA6vri",
    "outputId": "9f47611e-20f4-4cbe-f8e1-6fc8985a3022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03547081,  0.00757373, -0.02433911,  0.03694397, -0.00678332,\n",
       "        0.22896324, -0.14363428, -0.10989268, -0.00470791,  0.00489855,\n",
       "       -0.0438643 ,  0.02817945, -0.02272746,  0.02906044, -0.06188291,\n",
       "       -0.06740224,  0.09242145, -0.03410446, -0.00676464,  0.0223153 ,\n",
       "       -0.74102338, -0.08353484, -0.        ,  0.51007649, -0.01500953,\n",
       "        0.01169375, -0.04015249, -0.03565873, -0.03823784, -0.08391698])"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1585151577396,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "_3g5dYivoPV9",
    "outputId": "ae4a2082-f02e-4987-8004-94d3efc31711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0., -0., -0., -0., -0., -0., -0., -0., -0.,  0., -0., -0., -0.,\n",
       "       -0.,  0., -0., -0., -0.,  0., -0., -0., -0., -0., -0., -0., -0.,\n",
       "       -0., -0., -0., -0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1585151577397,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "fUOUmNvpR5nC",
    "outputId": "3ad3f140-333c-4209-8b9a-ae6bf4a1e4cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06, 1e-07, 1e-08, 1e-09]"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10**(-a) for a in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2513,
     "status": "ok",
     "timestamp": 1585151580196,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "DXzuKClBCs4p",
    "outputId": "fbc838ae-4cec-4e49-c1bc-0a9be99a3728"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.024782080877464807, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.034060672760041655, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010855088540207447, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6008258486931046, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.5021971614427043, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6818905484644757, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.250975508343892, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.9328027016403073, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4872323726697303, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6610136196923007, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.876734537023986, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.289868740452425, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.800395835015628, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.002548947645671, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.224229709203037, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.21323393516344, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.078848971040049, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.007340580654201, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.144750083923265, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.196429891705252, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.42784679978914, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.425987002428304, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.685139392665487, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.586488457971008, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.686068898579292, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.655612481708085, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.499427361692371, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.46350585523532, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.722718743768937, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.766185606559736, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.949749994086163, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.01780179427641, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.116978758161872, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.644200045394397, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.731174752568128, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.699505978791198, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.540543545734593, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.50885145474168, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.779479563868373, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.822296269669884, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.001065120089539, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.075824502324934, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.159213828911046, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.649982101303605, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.735673530730391, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.703891649755093, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.54464534274022, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.513383582020726, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.785145359856445, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.827898922188814, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.006186580188286, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.081615160099398, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.16342781667864, tolerance: 0.00842339832869081\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.650560415891151, tolerance: 0.008358938547486034\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.736123289888136, tolerance: 0.008546648044692738\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.704330179803321, tolerance: 0.008306424581005585\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.545055424650094, tolerance: 0.008279329608938547\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.513836769661847, tolerance: 0.008306424581005587\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.785711836686202, tolerance: 0.008332960893854746\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.828459103642833, tolerance: 0.008457262569832404\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.006698626062093, tolerance: 0.00822346368715084\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.082194111371935, tolerance: 0.008398328690807796\n",
      "  positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.163849121316513, tolerance: 0.00842339832869081\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 1e-05, 1e-06,\n",
       "                                   1e-07, 1e-08, 1e-09]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha' : [10**(-a) for a in range(10)]}\n",
    "lasso = Lasso()\n",
    "grid = GridSearchCV(lasso,param_grid=params, cv = 10)\n",
    "\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1585151580197,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "3ctUSVQyKgDi",
    "outputId": "9d289b0b-ac66-49b5-b9f7-897be73f518b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001}"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1797,
     "status": "ok",
     "timestamp": 1585151581150,
     "user": {
      "displayName": "othman benabidallah",
      "photoUrl": "",
      "userId": "09229019991848511339"
     },
     "user_tz": -60
    },
    "id": "wpiEw5EzKnTZ",
    "outputId": "ff6be4b9-1168-4b7b-a00a-2c00d528030b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True, False,  True,  True,  True, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.coef_!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHxyhoinK1VB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Régressions Régularisée - LASSO Exercice SOLUTION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
